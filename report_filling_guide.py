#!/usr/bin/env python3
"""
å®éªŒæŠ¥å‘Šå¡«å†™æŒ‡å—
ä»TensorBoardå’Œç»“æœæ–‡ä»¶ä¸­æå–æ•°æ®æ¥å¡«å†™æŠ¥å‘Šæ¨¡æ¿
"""

import os
import json
import pandas as pd
from datetime import datetime

def extract_dataset_info():
    """æå–æ•°æ®é›†ä¿¡æ¯"""
    print("=== 2.1 Caltech-101æ•°æ®é›†ä¿¡æ¯ ===")
    
    # è¿™äº›ä¿¡æ¯æ¥è‡ªä¹‹å‰çš„æ•°æ®é›†åˆ†æ
    dataset_info = {
        "æ€»æ ·æœ¬æ•°": 8677,
        "ç±»åˆ«æ•°é‡": 101,
        "æœ€å°‘æ ·æœ¬ç±»åˆ«": "inline_skate (31ä¸ªæ ·æœ¬)",
        "æœ€å¤šæ ·æœ¬ç±»åˆ«": "airplanes (800ä¸ªæ ·æœ¬)",
        "å¹³å‡æ¯ç±»æ ·æœ¬æ•°": 85.9
    }
    
    print("å¡«å†™å†…å®¹ï¼š")
    for key, value in dataset_info.items():
        print(f"- **{key}**: {value}")
    
    return dataset_info

def extract_data_split():
    """æå–æ•°æ®åˆ’åˆ†ä¿¡æ¯"""
    print("\n=== 2.2 æ•°æ®åˆ’åˆ†ä¿¡æ¯ ===")
    
    split_info = {
        "è®­ç»ƒé›†": "æ¯ç±»å‰30ä¸ªæ ·æœ¬ï¼Œå…±3030ä¸ªæ ·æœ¬",
        "éªŒè¯é›†": "ä»è®­ç»ƒé›†ä¸­åˆ†å‡º20%ï¼Œå…±606ä¸ªæ ·æœ¬", 
        "æµ‹è¯•é›†": "æ¯ç±»å‰©ä½™æ ·æœ¬ï¼Œå…±5647ä¸ªæ ·æœ¬"
    }
    
    print("å¡«å†™å†…å®¹ï¼š")
    for key, value in split_info.items():
        print(f"- **{key}**: {value}")
    
    return split_info

def extract_experiment_results():
    """ä»ç»“æœæ–‡ä»¶æå–å®éªŒç»“æœ"""
    print("\n=== 4.1 å®šé‡ç»“æœè¡¨æ ¼ ===")
    
    results_dir = 'results'
    result_files = [f for f in os.listdir(results_dir) if f.endswith('_results.json')]
    
    experiment_data = []
    
    for result_file in result_files:
        with open(os.path.join(results_dir, result_file), 'r') as f:
            data = json.load(f)
        
        # è§£æå®éªŒåç§°
        exp_name = data['experiment_name']
        config = data.get('experiment_config', {})
        
        # ä¼°ç®—è®­ç»ƒæ—¶é—´ï¼ˆåŸºäºè½®æ•°ï¼‰
        epochs = len(data.get('train_history', {}).get('train_losses', []))
        estimated_time = epochs * 2  # å‡è®¾æ¯è½®2åˆ†é’Ÿ
        
        # è·å–æ¨¡å‹åç§°å’Œå®éªŒç±»å‹
        parts = exp_name.split('_')
        if len(parts) >= 2:
            model_name = parts[0] if parts[0] != 'demo' else 'ResNet-18'
            exp_type = '_'.join(parts[1:]) if parts[0] != 'demo' else 'é¢„è®­ç»ƒå¾®è°ƒ'
        else:
            model_name = 'ResNet-18'
            exp_type = 'é¢„è®­ç»ƒå¾®è°ƒ'
        
        experiment_data.append({
            'æ¨¡å‹': model_name,
            'å®éªŒè®¾ç½®': exp_type,
            'éªŒè¯å‡†ç¡®ç‡(%)': f"{data.get('best_val_acc', 0):.2f}",
            'æµ‹è¯•å‡†ç¡®ç‡(%)': f"{data.get('test_acc', 0):.2f}",
            'è®­ç»ƒæ—¶é—´(åˆ†é’Ÿ)': estimated_time,
            'é¢„è®­ç»ƒ': config.get('pretrained', 'N/A'),
            'å­¦ä¹ ç‡': config.get('learning_rate', 'N/A'),
            'è®­ç»ƒè½®æ•°': epochs
        })
    
    # åˆ›å»ºè¡¨æ ¼
    df = pd.DataFrame(experiment_data)
    print("å¡«å†™å†…å®¹ï¼ˆå¤åˆ¶åˆ°æŠ¥å‘Šä¸­ï¼‰ï¼š")
    print(df.to_markdown(index=False))
    
    return experiment_data

def analyze_pretraining_impact(experiment_data):
    """åˆ†æé¢„è®­ç»ƒå½±å“"""
    print("\n=== 4.2 é¢„è®­ç»ƒå½±å“åˆ†æ ===")
    
    pretrained_results = [exp for exp in experiment_data if exp.get('é¢„è®­ç»ƒ') == True]
    scratch_results = [exp for exp in experiment_data if exp.get('é¢„è®­ç»ƒ') == False]
    
    if pretrained_results and scratch_results:
        pretrained_accs = [float(exp['æµ‹è¯•å‡†ç¡®ç‡(%)']) for exp in pretrained_results]
        scratch_accs = [float(exp['æµ‹è¯•å‡†ç¡®ç‡(%)']) for exp in scratch_results]
        
        pretrained_mean = sum(pretrained_accs) / len(pretrained_accs)
        scratch_mean = sum(scratch_accs) / len(scratch_accs)
        improvement = pretrained_mean - scratch_mean
        relative_improvement = (improvement / scratch_mean) * 100
        
        print("å¡«å†™å†…å®¹ï¼š")
        print(f"- **é¢„è®­ç»ƒæ¨¡å‹å¹³å‡å‡†ç¡®ç‡**: {pretrained_mean:.2f}%")
        print(f"- **ä»å¤´è®­ç»ƒå¹³å‡å‡†ç¡®ç‡**: {scratch_mean:.2f}%")
        print(f"- **æ€§èƒ½æå‡**: {improvement:.2f}ä¸ªç™¾åˆ†ç‚¹")
        print(f"- **ç›¸å¯¹æå‡**: {relative_improvement:.1f}%")
    else:
        print("ç›®å‰åªæœ‰é¢„è®­ç»ƒå®éªŒç»“æœï¼Œå»ºè®®è¿è¡Œä»å¤´è®­ç»ƒå®éªŒè¿›è¡Œå¯¹æ¯”ï¼š")
        print("python main.py --models resnet18 --experiments from_scratch")
    
    return experiment_data

def extract_best_model_info(experiment_data):
    """æå–æœ€ä½³æ¨¡å‹ä¿¡æ¯"""
    print("\n=== 7.3 æœ€ä½³æ¨¡å‹ ===")
    
    if experiment_data:
        best_exp = max(experiment_data, key=lambda x: float(x['æµ‹è¯•å‡†ç¡®ç‡(%)']))
        
        print("å¡«å†™å†…å®¹ï¼š")
        print(f"- **æ¨¡å‹**: {best_exp['æ¨¡å‹']}")
        print(f"- **é…ç½®**: {best_exp['å®éªŒè®¾ç½®']}")
        print(f"- **æµ‹è¯•å‡†ç¡®ç‡**: {best_exp['æµ‹è¯•å‡†ç¡®ç‡(%)']}%")
        print(f"- **éªŒè¯å‡†ç¡®ç‡**: {best_exp['éªŒè¯å‡†ç¡®ç‡(%)']}%")
        print(f"- **è®­ç»ƒè½®æ•°**: {best_exp['è®­ç»ƒè½®æ•°']}")
        
        # æŸ¥æ‰¾å¯¹åº”çš„æ¨¡å‹æ–‡ä»¶
        models_dir = 'models'
        if os.path.exists(models_dir):
            model_files = [f for f in os.listdir(models_dir) if f.endswith('.pth')]
            print(f"- **æ¨¡å‹æƒé‡æ–‡ä»¶**: {model_files}")
    
    return best_exp if experiment_data else None

def generate_tensorboard_instructions():
    """ç”ŸæˆTensorBoardæˆªå›¾æŒ‡å—"""
    print("\n=== 5. å¯è§†åŒ–ç»“æœ - TensorBoardæˆªå›¾æŒ‡å— ===")
    
    instructions = [
        "åœ¨TensorBoard (http://localhost:6006) ä¸­æˆªå–ä»¥ä¸‹å›¾è¡¨ï¼š",
        "",
        "**5.1 å¿…éœ€æˆªå›¾ï¼š**",
        "1. **è®­ç»ƒæ›²çº¿å›¾**ï¼š",
        "   - åœ¨SCALARSé¡µé¢é€‰æ‹© 'Loss_Comparison'",
        "   - åŒæ—¶é€‰æ‹© 'Accuracy_Comparison'", 
        "   - æˆªå›¾ä¿å­˜ä¸º 'å›¾1-è®­ç»ƒæ›²çº¿.png'",
        "",
        "2. **å­¦ä¹ ç‡æ›²çº¿å›¾**ï¼š",
        "   - é€‰æ‹© 'Learning_Rate'",
        "   - æˆªå›¾ä¿å­˜ä¸º 'å›¾2-å­¦ä¹ ç‡æ›²çº¿.png'",
        "",
        "3. **æ€§èƒ½æŒ‡æ ‡å›¾**ï¼š",
        "   - é€‰æ‹© 'Validation/Mean_Average_Metrics'",
        "   - è¿™æ˜¯mAPçš„æ›¿ä»£æŒ‡æ ‡",
        "   - æˆªå›¾ä¿å­˜ä¸º 'å›¾3-mAPæŒ‡æ ‡.png'",
        "",
        "4. **è¶…å‚æ•°å¯¹æ¯”**ï¼š",
        "   - åˆ‡æ¢åˆ°HPARAMSé¡µé¢",
        "   - æˆªå›¾ä¿å­˜ä¸º 'å›¾4-è¶…å‚æ•°å¯¹æ¯”.png'",
        "",
        "**5.2 å›¾è¡¨è¯´æ˜æ¨¡æ¿ï¼š**",
        "å›¾1: è®­ç»ƒæ›²çº¿æ˜¾ç¤ºæ¨¡å‹åœ¨ç¬¬Xè½®è¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼Œè®­ç»ƒæŸå¤±ä»Xä¸‹é™åˆ°X",
        "å›¾2: å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥æœ‰æ•ˆé™ä½äº†è®­ç»ƒåæœŸçš„å­¦ä¹ ç‡",  
        "å›¾3: éªŒè¯é›†ç»¼åˆæŒ‡æ ‡ï¼ˆç±»ä¼¼mAPï¼‰ç¨³å®šæå‡å¹¶æ”¶æ•›",
        "å›¾4: ä¸åŒè¶…å‚æ•°è®¾ç½®å¯¹æœ€ç»ˆæ€§èƒ½çš„å½±å“å¯¹æ¯”"
    ]
    
    for instruction in instructions:
        print(instruction)

def extract_class_performance():
    """æå–ç±»åˆ«æ€§èƒ½åˆ†æ"""
    print("\n=== 5.4 ç±»åˆ«æ€§èƒ½åˆ†æ ===")
    
    # ä»ç»“æœæ–‡ä»¶ä¸­æå–åˆ†ç±»æŠ¥å‘Š
    result_file = 'results/demo_resnet18_quick_results.json'
    
    if os.path.exists(result_file):
        with open(result_file, 'r') as f:
            data = json.load(f)
        
        classification_report = data.get('classification_report', {})
        
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„F1åˆ†æ•°
        class_scores = []
        for class_name, metrics in classification_report.items():
            if isinstance(metrics, dict) and 'f1-score' in metrics:
                class_scores.append({
                    'class': class_name,
                    'f1_score': metrics['f1-score'],
                    'support': metrics['support']
                })
        
        # æ’åºæ‰¾å‡ºæœ€å¥½å’Œæœ€å·®çš„ç±»åˆ«
        class_scores.sort(key=lambda x: x['f1_score'], reverse=True)
        
        print("å¡«å†™å†…å®¹ï¼š")
        print("**è¡¨ç°æœ€å¥½çš„ç±»åˆ«ï¼š**")
        for i, cls in enumerate(class_scores[:5]):
            print(f"{i+1}. {cls['class']}: F1={cls['f1_score']:.3f} (æ”¯æŒæ ·æœ¬:{cls['support']})")
        
        print("\n**è¡¨ç°æœ€å·®çš„ç±»åˆ«ï¼š**")
        for i, cls in enumerate(class_scores[-5:]):
            print(f"{i+1}. {cls['class']}: F1={cls['f1_score']:.3f} (æ”¯æŒæ ·æœ¬:{cls['support']})")

def generate_complete_filling_guide():
    """ç”Ÿæˆå®Œæ•´çš„å¡«å†™æŒ‡å—"""
    print("ğŸ¯ Caltech-101 å®éªŒæŠ¥å‘Šå¡«å†™æŒ‡å—")
    print("=" * 60)
    print(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # 1. æ•°æ®é›†ä¿¡æ¯
    dataset_info = extract_dataset_info()
    
    # 2. æ•°æ®åˆ’åˆ†
    split_info = extract_data_split()
    
    # 3. å®éªŒç»“æœ
    experiment_data = extract_experiment_results()
    
    # 4. é¢„è®­ç»ƒå½±å“åˆ†æ
    analyze_pretraining_impact(experiment_data)
    
    # 5. æœ€ä½³æ¨¡å‹ä¿¡æ¯
    best_model = extract_best_model_info(experiment_data)
    
    # 6. ç±»åˆ«æ€§èƒ½åˆ†æ
    extract_class_performance()
    
    # 7. TensorBoardæŒ‡å—
    generate_tensorboard_instructions()
    
    print("\n=== å…¶ä»–éœ€è¦å¡«å†™çš„éƒ¨åˆ† ===")
    print("**å®éªŒå®Œæˆæ—¶é—´**: ", datetime.now().strftime('%Y-%m-%d'))
    print("**å®éªŒè€…**: [è¯·å¡«å…¥æ‚¨çš„å§“å]")
    print("**è”ç³»æ–¹å¼**: [è¯·å¡«å…¥æ‚¨çš„é‚®ç®±]")
    print("**GitHubåœ°å€**: [è¯·å¡«å…¥æ‚¨çš„ä»“åº“é“¾æ¥]")
    
    print("\n=== å¿«é€Ÿå¡«å†™æ­¥éª¤ ===")
    steps = [
        "1. å¤åˆ¶ä¸Šé¢çš„æ•°æ®é›†ä¿¡æ¯åˆ°ç¬¬2èŠ‚",
        "2. å¤åˆ¶å®éªŒç»“æœè¡¨æ ¼åˆ°ç¬¬4.1èŠ‚",
        "3. å¤åˆ¶é¢„è®­ç»ƒå½±å“åˆ†æåˆ°ç¬¬4.2èŠ‚", 
        "4. æŒ‰ç…§æŒ‡å—åœ¨TensorBoardä¸­æˆªå›¾",
        "5. å¤åˆ¶æœ€ä½³æ¨¡å‹ä¿¡æ¯åˆ°ç¬¬7.3èŠ‚",
        "6. å¡«å†™ä¸ªäººä¿¡æ¯åˆ°ç¬¬10èŠ‚",
        "7. æ ¹æ®ç±»åˆ«åˆ†æå†™ç¬¬5.4èŠ‚çš„è®¨è®º"
    ]
    
    for step in steps:
        print(step)
    
    print(f"\nâœ… æŒ‡å—ç”Ÿæˆå®Œæˆï¼ç°åœ¨æ‚¨å¯ä»¥æŒ‰ç…§ä¸Šè¿°å†…å®¹å¡«å†™æŠ¥å‘Šæ¨¡æ¿äº†ã€‚")

if __name__ == '__main__':
    generate_complete_filling_guide() 