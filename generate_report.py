#!/usr/bin/env python3
"""
å®éªŒæŠ¥å‘Šç”Ÿæˆå™¨
è‡ªåŠ¨æ”¶é›†å®éªŒæ•°æ®å¹¶ç”Ÿæˆè¯¦ç»†çš„PDFæŠ¥å‘Š
"""

import os
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import numpy as np
from config import Config

class ExperimentReportGenerator:
    """å®éªŒæŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, results_dir='results', models_dir='models'):
        self.results_dir = results_dir
        self.models_dir = models_dir
        self.report_data = {}
        
    def collect_experiment_data(self):
        """æ”¶é›†æ‰€æœ‰å®éªŒæ•°æ®"""
        print("Collecting experiment data...")
        
        # æ”¶é›†ç»“æœæ–‡ä»¶
        result_files = [f for f in os.listdir(self.results_dir) 
                       if f.endswith('_results.json')]
        
        experiments = {}
        
        for result_file in result_files:
            try:
                with open(os.path.join(self.results_dir, result_file), 'r') as f:
                    data = json.load(f)
                    experiments[data['experiment_name']] = data
            except Exception as e:
                print(f"Error loading {result_file}: {e}")
        
        self.report_data['experiments'] = experiments
        
        # åˆ†ææ•°æ®é›†ç»Ÿè®¡
        self._collect_dataset_stats()
        
        # æ”¶é›†æ¨¡å‹ä¿¡æ¯
        self._collect_model_info()
        
        return self.report_data
    
    def _collect_dataset_stats(self):
        """æ”¶é›†æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        # è¿™é‡Œåº”è¯¥è¿è¡Œæ•°æ®é›†åˆ†æ
        # ä¸ºäº†ç¤ºä¾‹ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€äº›é»˜è®¤å€¼
        self.report_data['dataset'] = {
            'name': 'Caltech-101',
            'total_classes': 101,
            'train_samples_per_class': 30,
            'total_samples': 8677,  # è¿™ä¸ªéœ€è¦å®é™…è¿è¡Œè·å¾—
            'train_samples': 3030,
            'val_samples': 606,
            'test_samples': 5647
        }
    
    def _collect_model_info(self):
        """æ”¶é›†æ¨¡å‹ä¿¡æ¯"""
        models_info = {}
        
        # ä»å®éªŒç»“æœä¸­æå–æ¨¡å‹ä¿¡æ¯
        for exp_name, exp_data in self.report_data.get('experiments', {}).items():
            model_name = exp_name.split('_')[0]
            if model_name not in models_info:
                models_info[model_name] = {
                    'name': model_name,
                    'experiments': []
                }
            models_info[model_name]['experiments'].append(exp_name)
        
        self.report_data['models'] = models_info
    
    def generate_detailed_settings_table(self):
        """ç”Ÿæˆè¯¦ç»†çš„å®éªŒè®¾ç½®è¡¨æ ¼"""
        settings_data = []
        
        for exp_name, exp_data in self.report_data.get('experiments', {}).items():
            config = exp_data.get('experiment_config', {})
            
            # è§£ææ¨¡å‹åç§°å’Œå®éªŒç±»å‹
            parts = exp_name.split('_')
            model_name = parts[0]
            experiment_type = '_'.join(parts[1:])
            
            settings = {
                'Experiment Name': exp_name,
                'Model': model_name,
                'Experiment Type': experiment_type,
                'Pretrained': config.get('pretrained', 'N/A'),
                'Freeze Features': config.get('freeze_features', 'N/A'),
                'Learning Rate': config.get('learning_rate', 'N/A'),
                'Batch Size': Config.BATCH_SIZE,
                'Epochs Planned': config.get('num_epochs', 'N/A'),
                'Epochs Actual': len(exp_data.get('train_history', {}).get('train_losses', [])),
                'LR Scheduler': config.get('lr_scheduler', 'N/A'),
                'Step Size': config.get('step_size', 'N/A'),
                'Gamma': config.get('gamma', 'N/A'),
                'Optimizer': 'Adam',
                'Weight Decay': '1e-4',
                'Loss Function': 'CrossEntropyLoss',
                'Validation Split': Config.VAL_SPLIT,
                'Data Augmentation': Config.USE_AUGMENTATION,
                'Best Val Acc (%)': f"{exp_data.get('best_val_acc', 0):.2f}",
                'Test Acc (%)': f"{exp_data.get('test_acc', 0):.2f}",
                'Train Samples': self.report_data['dataset']['train_samples'],
                'Val Samples': self.report_data['dataset']['val_samples'],
                'Test Samples': self.report_data['dataset']['test_samples']
            }
            
            settings_data.append(settings)
        
        df = pd.DataFrame(settings_data)
        return df
    
    def generate_performance_summary(self):
        """ç”Ÿæˆæ€§èƒ½æ€»ç»“"""
        performance_data = []
        
        for exp_name, exp_data in self.report_data.get('experiments', {}).items():
            parts = exp_name.split('_')
            model_name = parts[0]
            experiment_type = '_'.join(parts[1:])
            
            config = exp_data.get('experiment_config', {})
            
            performance = {
                'Model': model_name,
                'Experiment': experiment_type,
                'Pretrained': config.get('pretrained', False),
                'Freeze Features': config.get('freeze_features', False),
                'Best Val Acc (%)': exp_data.get('best_val_acc', 0),
                'Test Acc (%)': exp_data.get('test_acc', 0),
                'Final Train Loss': exp_data.get('train_history', {}).get('train_losses', [0])[-1],
                'Final Val Loss': exp_data.get('train_history', {}).get('val_losses', [0])[-1],
                'Epochs Trained': len(exp_data.get('train_history', {}).get('train_losses', [])),
                'Learning Rate': config.get('learning_rate', 0)
            }
            
            performance_data.append(performance)
        
        df = pd.DataFrame(performance_data)
        return df
    
    def analyze_pretraining_impact(self):
        """åˆ†æé¢„è®­ç»ƒçš„å½±å“"""
        performance_df = self.generate_performance_summary()
        
        if len(performance_df) == 0:
            return {}
        
        pretrained_results = performance_df[performance_df['Pretrained'] == True]
        scratch_results = performance_df[performance_df['Pretrained'] == False]
        
        analysis = {}
        
        if len(pretrained_results) > 0 and len(scratch_results) > 0:
            pretrained_mean = pretrained_results['Test Acc (%)'].mean()
            scratch_mean = scratch_results['Test Acc (%)'].mean()
            improvement = pretrained_mean - scratch_mean
            
            analysis = {
                'pretrained_mean_acc': pretrained_mean,
                'scratch_mean_acc': scratch_mean,
                'absolute_improvement': improvement,
                'relative_improvement': improvement / scratch_mean * 100 if scratch_mean > 0 else 0,
                'best_pretrained': pretrained_results['Test Acc (%)'].max(),
                'best_scratch': scratch_results['Test Acc (%)'].max(),
                'pretrained_count': len(pretrained_results),
                'scratch_count': len(scratch_results)
            }
        
        return analysis
    
    def generate_tensorboard_instructions(self):
        """ç”ŸæˆTensorBoardä½¿ç”¨è¯´æ˜"""
        instructions = f"""
# TensorBoardå¯è§†åŒ–è¯´æ˜

## å¯åŠ¨TensorBoard
```bash
tensorboard --logdir {Config.TENSORBOARD_LOG_DIR}
```

ç„¶ååœ¨æµè§ˆå™¨ä¸­è®¿é—®: http://localhost:6006

## å¯è§†åŒ–å†…å®¹è¯´æ˜

### 1. SCALARSæ ‡ç­¾é¡µ
- **Loss/Train**: è®­ç»ƒé›†æŸå¤±æ›²çº¿
- **Loss/Validation**: éªŒè¯é›†æŸå¤±æ›²çº¿  
- **Accuracy/Train**: è®­ç»ƒé›†å‡†ç¡®ç‡æ›²çº¿
- **Accuracy/Validation**: éªŒè¯é›†å‡†ç¡®ç‡æ›²çº¿
- **Loss_Comparison**: è®­ç»ƒ/éªŒè¯æŸå¤±å¯¹æ¯”
- **Accuracy_Comparison**: è®­ç»ƒ/éªŒè¯å‡†ç¡®ç‡å¯¹æ¯”
- **Precision/Validation**: éªŒè¯é›†ç²¾ç¡®åº¦ï¼ˆç±»ä¼¼mAPæŒ‡æ ‡ï¼‰
- **Recall/Validation**: éªŒè¯é›†å¬å›ç‡
- **F1/Validation**: éªŒè¯é›†F1åˆ†æ•°
- **Validation/Mean_Average_Metrics**: éªŒè¯é›†ç»¼åˆæŒ‡æ ‡ï¼ˆç²¾ç¡®åº¦+å¬å›ç‡+F1çš„å¹³å‡å€¼ï¼‰
- **Learning_Rate**: å­¦ä¹ ç‡å˜åŒ–æ›²çº¿

### 2. HPARAMSæ ‡ç­¾é¡µ
- æŸ¥çœ‹æ‰€æœ‰å®éªŒçš„è¶…å‚æ•°å¯¹æ¯”
- åˆ†æä¸åŒè®¾ç½®å¯¹æ€§èƒ½çš„å½±å“

### 3. TEXTæ ‡ç­¾é¡µ
- æŸ¥çœ‹å®éªŒé…ç½®çš„è¯¦ç»†æ–‡æœ¬æè¿°

## é‡è¦å›¾è¡¨æˆªå›¾è¯´æ˜

### å¿…éœ€çš„æˆªå›¾ï¼š
1. **Loss_Comparison**: æ˜¾ç¤ºè®­ç»ƒ/éªŒè¯æŸå¤±å¯¹æ¯”æ›²çº¿
2. **Accuracy_Comparison**: æ˜¾ç¤ºè®­ç»ƒ/éªŒè¯å‡†ç¡®ç‡å¯¹æ¯”æ›²çº¿  
3. **Validation/Mean_Average_Metrics**: éªŒè¯é›†ç»¼åˆæ€§èƒ½æŒ‡æ ‡ï¼ˆä½œä¸ºmAPçš„æ›¿ä»£ï¼‰
4. **Learning_Rate**: å­¦ä¹ ç‡è°ƒåº¦æ›²çº¿
5. **HPARAMS**: è¶…å‚æ•°å¯¹æ¯”è¡¨æ ¼

### æˆªå›¾å»ºè®®ï¼š
- åœ¨SCALARSé¡µé¢ï¼Œé€‰æ‹©å¤šä¸ªå®éªŒè¿›è¡Œå¯¹æ¯”
- è°ƒæ•´å›¾è¡¨æ—¶é—´èŒƒå›´ï¼Œç¡®ä¿æ˜¾ç¤ºå®Œæ•´è®­ç»ƒè¿‡ç¨‹
- ä¿å­˜é«˜åˆ†è¾¨ç‡å›¾ç‰‡ç”¨äºæŠ¥å‘Š
"""
        return instructions
    
    def generate_markdown_report(self, output_file='detailed_experiment_report.md'):
        """ç”Ÿæˆè¯¦ç»†çš„markdownæŠ¥å‘Š"""
        
        # æ”¶é›†æ•°æ®
        self.collect_experiment_data()
        
        # ç”Ÿæˆå„ç§è¡¨æ ¼å’Œåˆ†æ
        settings_df = self.generate_detailed_settings_table()
        performance_df = self.generate_performance_summary()
        pretraining_analysis = self.analyze_pretraining_impact()
        tensorboard_instructions = self.generate_tensorboard_instructions()
        
        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_content = f"""# Caltech-101 å›¾åƒåˆ†ç±»å®éªŒè¯¦ç»†æŠ¥å‘Š

*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*

## 1. å®éªŒæ¦‚è¿°

### 1.1 å®éªŒç›®çš„
æœ¬å®éªŒæ—¨åœ¨é€šè¿‡å¾®è°ƒåœ¨ImageNetä¸Šé¢„è®­ç»ƒçš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œå®ç°å¯¹Caltech-101æ•°æ®é›†çš„å›¾åƒåˆ†ç±»ï¼Œå¹¶è§‚å¯Ÿä¸åŒè¶…å‚æ•°è®¾ç½®å’Œé¢„è®­ç»ƒç­–ç•¥å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚

### 1.2 æ•°æ®é›†ä¿¡æ¯
- **æ•°æ®é›†åç§°**: {self.report_data['dataset']['name']}
- **ç±»åˆ«æ•°é‡**: {self.report_data['dataset']['total_classes']}
- **æ¯ç±»è®­ç»ƒæ ·æœ¬**: {self.report_data['dataset']['train_samples_per_class']}
- **è®­ç»ƒæ ·æœ¬æ€»æ•°**: {self.report_data['dataset']['train_samples']}
- **éªŒè¯æ ·æœ¬æ€»æ•°**: {self.report_data['dataset']['val_samples']}
- **æµ‹è¯•æ ·æœ¬æ€»æ•°**: {self.report_data['dataset']['test_samples']}

## 2. è¯¦ç»†å®éªŒè®¾ç½®

### 2.1 å®Œæ•´é…ç½®è¡¨

{settings_df.to_markdown(index=False)}

### 2.2 æ•°æ®é¢„å¤„ç†è®¾ç½®
- **å›¾åƒå°ºå¯¸**: 224Ã—224åƒç´ 
- **æ ‡å‡†åŒ–**: ImageNetæ ‡å‡† (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
- **æ•°æ®å¢å¼º**: éšæœºæ°´å¹³ç¿»è½¬ã€éšæœºæ—‹è½¬(Â±15Â°)ã€é¢œè‰²æŠ–åŠ¨ã€éšæœºè£å‰ª
- **è®­ç»ƒ/éªŒè¯/æµ‹è¯•åˆ’åˆ†**: æŒ‰Caltech-101æ ‡å‡†ï¼Œæ¯ç±»30ä¸ªè®­ç»ƒæ ·æœ¬

### 2.3 è®­ç»ƒé…ç½®
- **æŸå¤±å‡½æ•°**: CrossEntropyLoss
- **ä¼˜åŒ–å™¨**: Adam
- **æƒé‡è¡°å‡**: 1e-4
- **æ‰¹å¤§å°**: {Config.BATCH_SIZE}
- **æ—©åœç­–ç•¥**: éªŒè¯å‡†ç¡®ç‡{Config.EARLY_STOPPING_PATIENCE}è½®ä¸æå‡åˆ™åœæ­¢
- **è®¾å¤‡**: è‡ªåŠ¨æ£€æµ‹CUDA/CPU

## 3. å®éªŒç»“æœæ±‡æ€»

### 3.1 æ€§èƒ½å¯¹æ¯”è¡¨

{performance_df.to_markdown(index=False)}

### 3.2 é¢„è®­ç»ƒå½±å“åˆ†æ
"""

        if pretraining_analysis:
            report_content += f"""
- **é¢„è®­ç»ƒæ¨¡å‹å¹³å‡å‡†ç¡®ç‡**: {pretraining_analysis['pretrained_mean_acc']:.2f}%
- **ä»å¤´è®­ç»ƒå¹³å‡å‡†ç¡®ç‡**: {pretraining_analysis['scratch_mean_acc']:.2f}%  
- **ç»å¯¹æ€§èƒ½æå‡**: {pretraining_analysis['absolute_improvement']:.2f}ä¸ªç™¾åˆ†ç‚¹
- **ç›¸å¯¹æ€§èƒ½æå‡**: {pretraining_analysis['relative_improvement']:.1f}%
- **æœ€ä½³é¢„è®­ç»ƒæ¨¡å‹å‡†ç¡®ç‡**: {pretraining_analysis['best_pretrained']:.2f}%
- **æœ€ä½³ä»å¤´è®­ç»ƒå‡†ç¡®ç‡**: {pretraining_analysis['best_scratch']:.2f}%
"""
        else:
            report_content += "\n- æš‚æ— è¶³å¤Ÿæ•°æ®è¿›è¡Œé¢„è®­ç»ƒå½±å“åˆ†æ\n"

        report_content += f"""

## 4. TensorBoardå¯è§†åŒ–æŒ‡å—

{tensorboard_instructions}

## 5. æ¨¡å‹æƒé‡æ–‡ä»¶

ä»¥ä¸‹æ¨¡å‹æƒé‡æ–‡ä»¶å·²ä¿å­˜åœ¨ `{self.models_dir}/` ç›®å½•ä¸­ï¼š

"""
        
        # åˆ—å‡ºæ¨¡å‹æ–‡ä»¶
        if os.path.exists(self.models_dir):
            model_files = [f for f in os.listdir(self.models_dir) if f.endswith('.pth')]
            for model_file in model_files:
                report_content += f"- `{model_file}`\n"
        
        report_content += f"""

## 6. ç»“æœæ–‡ä»¶è¯´æ˜

### 6.1 ç»“æœç›®å½•ç»“æ„
```
{self.results_dir}/
â”œâ”€â”€ *_results.json          # å„å®éªŒçš„è¯¦ç»†ç»“æœ
â”œâ”€â”€ *_confusion_matrix.png  # æ··æ·†çŸ©é˜µå›¾
â”œâ”€â”€ *_training_curves.png   # è®­ç»ƒæ›²çº¿å›¾
â”œâ”€â”€ comparison_results.csv  # å®éªŒå¯¹æ¯”è¡¨
â””â”€â”€ accuracy_comparison.png # å‡†ç¡®ç‡å¯¹æ¯”å›¾
```

### 6.2 TensorBoardæ—¥å¿—
```
{Config.TENSORBOARD_LOG_DIR}/
â””â”€â”€ [experiment_name]/      # å„å®éªŒçš„TensorBoardæ—¥å¿—
```

## 7. ä»£ç è¿è¡Œè®°å½•

### 7.1 æ•°æ®é›†åˆ†æ
```bash
python main.py --analyze-only
```

### 7.2 å®Œæ•´å®éªŒè¿è¡Œ
```bash
python main.py --models resnet18 --experiments pretrained_finetune from_scratch
```

### 7.3 TensorBoardå¯åŠ¨
```bash
tensorboard --logdir {Config.TENSORBOARD_LOG_DIR}
```

## 8. è®ºæ–‡æ’°å†™å»ºè®®

### 8.1 å®éªŒè®¾ç½®ç« èŠ‚
å¯ä»¥ç›´æ¥å¼•ç”¨ç¬¬2èŠ‚çš„è¯¦ç»†é…ç½®è¡¨ï¼ŒåŒ…å«äº†æ‰€æœ‰å¿…è¦çš„å®éªŒå‚æ•°ã€‚

### 8.2 ç»“æœåˆ†æç« èŠ‚
- å¼•ç”¨ç¬¬3èŠ‚çš„æ€§èƒ½å¯¹æ¯”è¡¨
- ä»TensorBoardæˆªå–è®­ç»ƒ/éªŒè¯æ›²çº¿å›¾
- åˆ†æé¢„è®­ç»ƒvsä»å¤´è®­ç»ƒçš„æ€§èƒ½å·®å¼‚

### 8.3 å›¾è¡¨å»ºè®®
1. è®­ç»ƒ/éªŒè¯æŸå¤±æ›²çº¿å¯¹æ¯”å›¾
2. è®­ç»ƒ/éªŒè¯å‡†ç¡®ç‡æ›²çº¿å¯¹æ¯”å›¾  
3. ä¸åŒå®éªŒè®¾ç½®çš„æœ€ç»ˆå‡†ç¡®ç‡æŸ±çŠ¶å›¾
4. æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾
5. å­¦ä¹ ç‡è°ƒåº¦æ›²çº¿

---

*æŠ¥å‘Šç”Ÿæˆå™¨ç‰ˆæœ¬: 1.0*  
*è”ç³»æ–¹å¼: [your.email@example.com]*
"""

        # ä¿å­˜æŠ¥å‘Š
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"è¯¦ç»†å®éªŒæŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
        
        # åŒæ—¶ä¿å­˜è¡¨æ ¼ä¸ºCSV
        settings_df.to_csv('detailed_experiment_settings.csv', index=False)
        performance_df.to_csv('performance_summary.csv', index=False)
        
        print("CSVæ–‡ä»¶å·²ç”Ÿæˆ:")
        print("- detailed_experiment_settings.csv")
        print("- performance_summary.csv")
        
        return output_file

def main():
    """ä¸»å‡½æ•°"""
    generator = ExperimentReportGenerator()
    report_file = generator.generate_markdown_report()
    
    print(f"\nğŸ‰ å®éªŒæŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
    print(f"ğŸ“„ æŠ¥å‘Šæ–‡ä»¶: {report_file}")
    print(f"ğŸ“Š è¡¨æ ¼æ–‡ä»¶: detailed_experiment_settings.csv, performance_summary.csv")
    print(f"\nğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œ:")
    print(f"1. æŸ¥çœ‹ç”Ÿæˆçš„markdownæŠ¥å‘Š")
    print(f"2. å¯åŠ¨TensorBoard: tensorboard --logdir {Config.TENSORBOARD_LOG_DIR}")
    print(f"3. åœ¨TensorBoardä¸­æˆªå–æ‰€éœ€å›¾è¡¨")
    print(f"4. å°†markdownè½¬æ¢ä¸ºPDFæŠ¥å‘Š")

if __name__ == '__main__':
    main() 